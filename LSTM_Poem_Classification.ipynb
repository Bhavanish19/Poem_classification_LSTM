{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZP3JgIEj_E5",
        "outputId": "544d2380-43d3-49d9-b533-db13adc064a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/128.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.23.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner --upgrade -q\n",
        "!pip install keras_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# standard library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from sklearn import preprocessing\n",
        "warnings.simplefilter('ignore')\n",
        "import random\n",
        "\n",
        "# neural network library\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "# from tensorflow.keras import preprocessing\n",
        "from keras_preprocessing.text import Tokenizer\n",
        "import kerastuner as kt"
      ],
      "metadata": {
        "id": "p8gNgh5qkF-C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Data\n",
        "train_file = 'https://raw.githubusercontent.com/BhavanishDhamnaskar/poem_d/main/Poem_classification%20-%20train_data.csv'\n",
        "val_file = 'https://raw.githubusercontent.com/BhavanishDhamnaskar/poem_d/main/Poem_classification%20-%20test_data.csv'\n",
        "\n",
        "train = pd.read_csv(train_file)\n",
        "val = pd.read_csv(val_file, error_bad_lines=False, warn_bad_lines=True)\n",
        "\n",
        "# Drop NULLs in training data\n",
        "train.dropna(inplace=True)\n",
        "train.reset_index(inplace=True, drop=True)\n",
        "\n",
        "# Stats\n",
        "print(f\"Training records: {train.shape[0]}, Validation records: {val.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubn56-lqkGAq",
        "outputId": "aaf7c964-39aa-4898-c599-2889f4c56ef4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training records: 837, Validation records: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# params\n",
        "max_features = int(sum([len(txt.split()) for txt in train['Poem']]) /2) # top n words to consider\n",
        "maxlen = max([len(txt.split()) for txt in train['Poem']])  # first n words to consider"
      ],
      "metadata": {
        "id": "rFGd2TGTkGDQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoding\n",
        "''' affection: 0, death: 1, environment: 2, music: 3 '''\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "train['Genre_Code']= label_encoder.fit_transform(train['Genre'])\n",
        "val['Genre_Code']= label_encoder.fit_transform(val['Genre'])"
      ],
      "metadata": {
        "id": "Rstq-kawkGF4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pre-processing\n",
        "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "\n",
        "# training data\n",
        "tokenizer.fit_on_texts(train['Poem'])\n",
        "x_train = np.array(tokenizer.texts_to_sequences(train['Poem']))\n",
        "y_train = np.array(train['Genre_Code'])\n",
        "\n",
        "# validation data\n",
        "tokenizer.fit_on_texts(val['Poem'])\n",
        "x_val = np.array(tokenizer.texts_to_sequences(val['Poem']))\n",
        "y_val = np.array(val['Genre_Code'])\n",
        "\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "gMv8SihdkGIf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input for variable-length sequences of integers\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "# Embed each integer in a 128-dimensional vector\n",
        "x = layers.Embedding(max_features, 128)(inputs)\n",
        "# Add 2 bidirectional LSTMs\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "# Add a classifier\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "DRWWGicVkGLI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter tuning the base model\n",
        "def build_model(hp):\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "\n",
        "  inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "  x = layers.Embedding(max_features, hp_units)(inputs)\n",
        "  x = layers.Bidirectional(layers.LSTM(hp_units, return_sequences=True))(x)\n",
        "  x = layers.Bidirectional(layers.LSTM(hp_units))(x)\n",
        "  outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "  model = keras.Model(inputs, outputs)\n",
        "\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "YCq_STz4kGNJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the tuner\n",
        "tuner = kt.Hyperband(\n",
        "                      build_model, # the hypermodel\n",
        "                      objective='val_accuracy', # objective to optimize\n",
        "                      max_epochs=10,\n",
        "                      factor=3, # factor which you have seen above\n",
        "                    )"
      ],
      "metadata": {
        "id": "hoOUUc4QkGPx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start the search and get the best model\n",
        "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val), callbacks=[stop_early])\n",
        "best_param = tuner.get_best_hyperparameters()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jix2FuZoZ6f",
        "outputId": "ba0d55f6-1214-4b1e-cd6b-bafc8c9d8b71"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 36s]\n",
            "val_accuracy: 0.6666666865348816\n",
            "\n",
            "Best val_accuracy So Far: 0.6666666865348816\n",
            "Total elapsed time: 00h 14m 03s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"best parameters are:\\n\",best_param.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IwzY3nKkGVg",
        "outputId": "60423a9e-e7a5-4e3a-ba44-ca37bfb3a1e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best parameters are:\n",
            " {'units': 224, 'learning_rate': 0.01, 'tuner/epochs': 2, 'tuner/initial_epoch': 0, 'tuner/bracket': 2, 'tuner/round': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build model with optimal parameters"
      ],
      "metadata": {
        "id": "ljtM1G_Ik2Lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(lr):\n",
        "  if lr == 0.01:\n",
        "    return 1e-2\n",
        "  elif lr == 0.001:\n",
        "    return 1e-3\n",
        "  elif lr == 0.0001:\n",
        "    return  1e-4"
      ],
      "metadata": {
        "id": "75abF8EssxFf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# params for optimization\n",
        "unit = best_param.values['units']\n",
        "epoch = best_param.values['tuner/epochs']\n",
        "size = 32\n",
        "lr = get_lr(best_param.values['learning_rate'])"
      ],
      "metadata": {
        "id": "_tnhOKb7kGYJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# updating the base model\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int32\")\n",
        "x = layers.Embedding(max_features, unit)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(unit, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(unit))(x)\n",
        "# Add a classifier\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "2wS64N3YkGbA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling & fitting the model\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
        "history = model.fit(x_train, y_train, batch_size=size, epochs=epoch, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqagf6x-kGf7",
        "outputId": "bb69bccb-246a-47d8-962b-503618616aed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "27/27 [==============================] - 12s 181ms/step - loss: nan - accuracy: 0.1697 - val_loss: nan - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "27/27 [==============================] - 4s 161ms/step - loss: nan - accuracy: 0.1685 - val_loss: nan - val_accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = \"{:.2f}\".format(history.history.get('val_accuracy')[0])\n",
        "print(f\"Model's Optimized Accuracy is: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cMmwJ51kGik",
        "outputId": "84227870-62e2-4cfe-b27b-2b63659a6363"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's Optimized Accuracy is: 0.67\n"
          ]
        }
      ]
    }
  ]
}